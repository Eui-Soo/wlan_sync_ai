{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 100000 samples, validate on 50000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 64s 642us/step - loss: 682.3051 - mse: 682.3052 - val_loss: 574.4439 - val_mse: 574.4438\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 61s 611us/step - loss: 247.8394 - mse: 247.8393 - val_loss: 437.4211 - val_mse: 437.4210\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 59s 591us/step - loss: 195.5015 - mse: 195.5014 - val_loss: 336.6491 - val_mse: 336.6490\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 59s 593us/step - loss: 170.3051 - mse: 170.3051 - val_loss: 301.2816 - val_mse: 301.2816\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 60s 596us/step - loss: 155.5351 - mse: 155.5351 - val_loss: 298.5330 - val_mse: 298.5331\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 59s 589us/step - loss: 142.4166 - mse: 142.4166 - val_loss: 313.4085 - val_mse: 313.4084\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 59s 589us/step - loss: 134.7421 - mse: 134.7421 - val_loss: 362.1506 - val_mse: 362.1506\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 59s 587us/step - loss: 120.1803 - mse: 120.1803 - val_loss: 307.9186 - val_mse: 307.9186\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 58s 581us/step - loss: 108.8105 - mse: 108.8106 - val_loss: 285.1059 - val_mse: 285.1058\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 59s 592us/step - loss: 96.9729 - mse: 96.9729 - val_loss: 321.0964 - val_mse: 321.0963\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 60s 598us/step - loss: 83.0587 - mse: 83.0587 - val_loss: 284.8460 - val_mse: 284.8461\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 59s 590us/step - loss: 71.7840 - mse: 71.7840 - val_loss: 283.5560 - val_mse: 283.5562\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 60s 601us/step - loss: 59.5027 - mse: 59.5027 - val_loss: 338.8896 - val_mse: 338.8896\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 59s 588us/step - loss: 51.1822 - mse: 51.1822 - val_loss: 293.4101 - val_mse: 293.4102\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 59s 591us/step - loss: 44.8884 - mse: 44.8884 - val_loss: 345.2402 - val_mse: 345.2402\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 59s 592us/step - loss: 43.4923 - mse: 43.4923 - val_loss: 294.8444 - val_mse: 294.8443\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 59s 586us/step - loss: 39.6261 - mse: 39.6261 - val_loss: 278.1353 - val_mse: 278.1354\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 60s 603us/step - loss: 31.8278 - mse: 31.8279 - val_loss: 293.4353 - val_mse: 293.4355\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 60s 596us/step - loss: 31.4496 - mse: 31.4496 - val_loss: 299.3323 - val_mse: 299.3323\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 58s 581us/step - loss: 32.1022 - mse: 32.1021 - val_loss: 279.0827 - val_mse: 279.0826\n",
      "Train on 100000 samples, validate on 50000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 58s 585us/step - loss: 661.2156 - mse: 661.2158 - val_loss: 484.2905 - val_mse: 484.2906\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 59s 595us/step - loss: 230.7188 - mse: 230.7187 - val_loss: 309.6791 - val_mse: 309.6791\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 59s 591us/step - loss: 166.7687 - mse: 166.7686 - val_loss: 202.4815 - val_mse: 202.4815\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 59s 591us/step - loss: 125.6528 - mse: 125.6528 - val_loss: 174.1354 - val_mse: 174.1354\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 60s 600us/step - loss: 110.0422 - mse: 110.0422 - val_loss: 176.8895 - val_mse: 176.8895\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 59s 590us/step - loss: 96.1474 - mse: 96.1474 - val_loss: 151.7136 - val_mse: 151.7136\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 59s 589us/step - loss: 88.5330 - mse: 88.5330 - val_loss: 150.6167 - val_mse: 150.6167\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 59s 588us/step - loss: 82.2270 - mse: 82.2270 - val_loss: 141.1253 - val_mse: 141.1254\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 59s 589us/step - loss: 72.4093 - mse: 72.4093 - val_loss: 145.0717 - val_mse: 145.0718\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 59s 589us/step - loss: 65.5295 - mse: 65.5295 - val_loss: 159.3993 - val_mse: 159.3993\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 59s 585us/step - loss: 60.4131 - mse: 60.4131 - val_loss: 139.1998 - val_mse: 139.1998\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 58s 579us/step - loss: 52.4517 - mse: 52.4517 - val_loss: 130.5367 - val_mse: 130.5368\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 59s 589us/step - loss: 42.6256 - mse: 42.6256 - val_loss: 136.1912 - val_mse: 136.1911\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 58s 585us/step - loss: 39.9137 - mse: 39.9137 - val_loss: 133.2733 - val_mse: 133.2733\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 59s 586us/step - loss: 34.2748 - mse: 34.2748 - val_loss: 147.2033 - val_mse: 147.2032\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 62s 621us/step - loss: 32.5838 - mse: 32.5839 - val_loss: 136.9110 - val_mse: 136.9110\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 60s 595us/step - loss: 28.2300 - mse: 28.2300 - val_loss: 131.4482 - val_mse: 131.4482\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 59s 594us/step - loss: 26.4425 - mse: 26.4425 - val_loss: 134.0292 - val_mse: 134.0292\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 59s 590us/step - loss: 25.0320 - mse: 25.0320 - val_loss: 130.9964 - val_mse: 130.9964\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 58s 584us/step - loss: 23.5666 - mse: 23.5666 - val_loss: 137.0000 - val_mse: 137.0000\n",
      "Train on 100000 samples, validate on 50000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 60s 600us/step - loss: 584.8532 - mse: 584.8536 - val_loss: 435.3540 - val_mse: 435.3541\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 59s 593us/step - loss: 205.8106 - mse: 205.8106 - val_loss: 266.4201 - val_mse: 266.4200\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 60s 600us/step - loss: 149.7652 - mse: 149.7652 - val_loss: 194.1604 - val_mse: 194.1604\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 60s 599us/step - loss: 118.8219 - mse: 118.8219 - val_loss: 164.2617 - val_mse: 164.2617\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 59s 587us/step - loss: 107.2640 - mse: 107.2639 - val_loss: 158.8229 - val_mse: 158.8229\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 59s 586us/step - loss: 93.3856 - mse: 93.3856 - val_loss: 202.1690 - val_mse: 202.1691\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 62s 616us/step - loss: 87.0613 - mse: 87.0613 - val_loss: 123.0279 - val_mse: 123.0279\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 60s 603us/step - loss: 73.5221 - mse: 73.5222 - val_loss: 150.7169 - val_mse: 150.7169\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 61s 605us/step - loss: 66.2450 - mse: 66.2450 - val_loss: 122.7176 - val_mse: 122.7176\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 58s 575us/step - loss: 58.1107 - mse: 58.1107 - val_loss: 134.0220 - val_mse: 134.0220\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 57s 574us/step - loss: 50.0176 - mse: 50.0176 - val_loss: 127.2942 - val_mse: 127.2942\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 57s 573us/step - loss: 42.6783 - mse: 42.6783 - val_loss: 117.6282 - val_mse: 117.6282\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 59s 592us/step - loss: 35.4583 - mse: 35.4583 - val_loss: 132.9595 - val_mse: 132.9596\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 60s 596us/step - loss: 32.2900 - mse: 32.2900 - val_loss: 117.7067 - val_mse: 117.7067\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 59s 593us/step - loss: 30.2507 - mse: 30.2508 - val_loss: 111.6608 - val_mse: 111.6608\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 59s 593us/step - loss: 26.6030 - mse: 26.6030 - val_loss: 110.5228 - val_mse: 110.5228\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 59s 590us/step - loss: 26.8424 - mse: 26.8424 - val_loss: 106.8873 - val_mse: 106.8873\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 61s 613us/step - loss: 24.1567 - mse: 24.1567 - val_loss: 106.4009 - val_mse: 106.4008\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 61s 608us/step - loss: 24.1612 - mse: 24.1612 - val_loss: 112.7785 - val_mse: 112.7785\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 60s 601us/step - loss: 26.0222 - mse: 26.0222 - val_loss: 108.8736 - val_mse: 108.8736\n",
      "Train on 100000 samples, validate on 50000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 61s 609us/step - loss: 730.7446 - mse: 730.7446 - val_loss: 562.7912 - val_mse: 562.7914\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 58s 581us/step - loss: 222.3109 - mse: 222.3109 - val_loss: 285.8020 - val_mse: 285.8020\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 59s 594us/step - loss: 149.7432 - mse: 149.7432 - val_loss: 153.0586 - val_mse: 153.0586\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 61s 608us/step - loss: 110.6729 - mse: 110.6729 - val_loss: 120.7561 - val_mse: 120.7560\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 59s 589us/step - loss: 93.9280 - mse: 93.9280 - val_loss: 157.8623 - val_mse: 157.8623\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 59s 595us/step - loss: 82.8462 - mse: 82.8463 - val_loss: 114.0797 - val_mse: 114.0797\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 58s 580us/step - loss: 74.0192 - mse: 74.0192 - val_loss: 97.8406 - val_mse: 97.8405\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 58s 584us/step - loss: 68.1335 - mse: 68.1335 - val_loss: 96.4280 - val_mse: 96.4280\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 59s 590us/step - loss: 64.3827 - mse: 64.3827 - val_loss: 90.2303 - val_mse: 90.2302\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 59s 592us/step - loss: 55.1918 - mse: 55.1917 - val_loss: 99.6334 - val_mse: 99.6334\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 59s 593us/step - loss: 54.0266 - mse: 54.0266 - val_loss: 81.3241 - val_mse: 81.3241\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 58s 578us/step - loss: 44.7908 - mse: 44.7908 - val_loss: 113.2388 - val_mse: 113.2388\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 58s 578us/step - loss: 43.0540 - mse: 43.0540 - val_loss: 72.5757 - val_mse: 72.5757\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 58s 583us/step - loss: 37.6539 - mse: 37.6539 - val_loss: 97.8637 - val_mse: 97.8637\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 58s 584us/step - loss: 36.9023 - mse: 36.9023 - val_loss: 72.8861 - val_mse: 72.8861\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 60s 595us/step - loss: 32.5254 - mse: 32.5254 - val_loss: 70.5380 - val_mse: 70.5380\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 59s 589us/step - loss: 28.0523 - mse: 28.0523 - val_loss: 75.1404 - val_mse: 75.1403\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 59s 590us/step - loss: 26.9278 - mse: 26.9278 - val_loss: 74.1611 - val_mse: 74.1610\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 58s 585us/step - loss: 26.5104 - mse: 26.5104 - val_loss: 72.9220 - val_mse: 72.9220\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 58s 581us/step - loss: 22.0403 - mse: 22.0403 - val_loss: 86.8725 - val_mse: 86.8725\n",
      "Train on 100000 samples, validate on 50000 samples\n",
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 60s 597us/step - loss: 752.6170 - mse: 752.6168 - val_loss: 445.0030 - val_mse: 445.0030\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 58s 584us/step - loss: 210.7839 - mse: 210.7840 - val_loss: 263.5581 - val_mse: 263.5581\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 59s 586us/step - loss: 128.4181 - mse: 128.4181 - val_loss: 151.2336 - val_mse: 151.2337\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 60s 600us/step - loss: 101.6524 - mse: 101.6524 - val_loss: 106.9729 - val_mse: 106.9728\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 60s 599us/step - loss: 82.3658 - mse: 82.3658 - val_loss: 100.6963 - val_mse: 100.6963\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 60s 597us/step - loss: 72.1726 - mse: 72.1726 - val_loss: 86.3315 - val_mse: 86.3316\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 58s 584us/step - loss: 68.1609 - mse: 68.1609 - val_loss: 81.7020 - val_mse: 81.7020\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 59s 593us/step - loss: 56.4178 - mse: 56.4178 - val_loss: 74.8362 - val_mse: 74.8362\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 59s 589us/step - loss: 54.1858 - mse: 54.1859 - val_loss: 78.4692 - val_mse: 78.4692\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 59s 589us/step - loss: 50.8882 - mse: 50.8882 - val_loss: 81.9556 - val_mse: 81.9556\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 59s 586us/step - loss: 44.0673 - mse: 44.0673 - val_loss: 71.4567 - val_mse: 71.4567\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 59s 588us/step - loss: 38.7334 - mse: 38.7334 - val_loss: 69.8643 - val_mse: 69.8643\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 59s 588us/step - loss: 37.3960 - mse: 37.3960 - val_loss: 65.5084 - val_mse: 65.5084\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 58s 585us/step - loss: 36.8902 - mse: 36.8902 - val_loss: 71.4021 - val_mse: 71.4021\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 59s 589us/step - loss: 30.0419 - mse: 30.0419 - val_loss: 67.5565 - val_mse: 67.5565\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 59s 588us/step - loss: 25.8715 - mse: 25.8715 - val_loss: 63.9317 - val_mse: 63.9316\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 60s 599us/step - loss: 28.9862 - mse: 28.9862 - val_loss: 62.8807 - val_mse: 62.8807\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 60s 598us/step - loss: 25.4076 - mse: 25.4076 - val_loss: 62.4369 - val_mse: 62.4369\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 59s 587us/step - loss: 21.7011 - mse: 21.7011 - val_loss: 61.1221 - val_mse: 61.1221\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 60s 597us/step - loss: 20.2577 - mse: 20.2577 - val_loss: 55.5532 - val_mse: 55.5532\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model\n",
    "channel_model=['B','C','D','E','F']\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "#channel_model=['B']\n",
    "\n",
    "for model_idx in channel_model:\n",
    "    filepath='./wlan_train_set_model_%s.mat' % model_idx\n",
    "    f=h5py.File(filepath,'r')\n",
    "    train_data=np.array(f['Train_data'][:])\n",
    "    cfo_label=np.array(f['Train_cfo_label'][:])/1e3\n",
    "    filepath_test='D:/논문연구/WLAN/wlan_test_set_CFO_model_{0}_SNR(-5).mat' .format(model_idx)\n",
    "    f_test=h5py.File(filepath_test,'r')\n",
    "    valid_data=np.array(f_test['Test_data'][:])\n",
    "    valid_label=np.array(f_test['Test_data_cfo_label'][:])/1e3\n",
    "    input_data=Input(shape=(11,864,1))\n",
    "    x=layers.Conv2D(32,(3,3),padding='same',activation='relu',kernel_initializer='he_normal')(input_data)\n",
    "    x=layers.MaxPooling2D((1,4),padding='same')(x)\n",
    "    x_skip1=layers.Conv2D(128,(1,1),strides=(1,2),padding='same',activation='relu',kernel_initializer='he_normal')(x)\n",
    "    x=layers.Conv2D(64,(3,3),padding='same',activation='relu',kernel_initializer='he_normal')(x)\n",
    "    x=layers.MaxPooling2D((1,2),padding='same')(x)\n",
    "    x=layers.Conv2D(128,(3,3),padding='same',activation='relu',kernel_initializer='he_normal')(x)\n",
    "    x=layers.add([x_skip1,x])\n",
    "    x=layers.MaxPooling2D((1,4),padding='same')(x)\n",
    "    x_skip2=layers.Conv2D(512,(1,1),strides=(1,2),padding='same',activation='relu',kernel_initializer='he_normal')(x)\n",
    "    x=layers.Conv2D(256,(3,3),padding='same',activation='relu',kernel_initializer='he_normal')(x)\n",
    "    x=layers.MaxPooling2D((1,2),padding='same')(x)\n",
    "    x=layers.Conv2D(512,(3,3),padding='same',activation='relu',kernel_initializer='he_normal')(x)\n",
    "    x=layers.add([x_skip2,x])\n",
    "    x=layers.Flatten()(x)\n",
    "    #x=layers.Dense(512,activation='relu',kernel_initializer='he_normal')(x)\n",
    "    x=layers.Dense(1,name='cfo')(x)\n",
    "    model= Model(input_data,x)\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001),\n",
    "                loss={'cfo':'mse'},\n",
    "                loss_weights={'cfo':1},\n",
    "                metrics={'cfo':'mse'})\n",
    "    model.fit(train_data,{'cfo':cfo_label},epochs=20,batch_size=256,validation_data=(valid_data,valid_label))\n",
    "    \n",
    "    model_name='wlan_CFO_model_%s_v3.h5' % model_idx\n",
    "    model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
